{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "import models\n",
    "import train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'l:\\\\Documents\\\\(8) Cairo Uni Spring 2023\\\\SBEN454_Machine_Learning\\\\Tasks & Projects\\\\Term Project\\\\CGM_Prediction_LSTM\\\\code\\\\models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train_lstm)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1289719\n",
    "series_min_len = 144 #12hrs\n",
    "pred_horizon = 12 # 1hr\n",
    "input_size = series_min_len - pred_horizon\n",
    "output_size = pred_horizon\n",
    "\n",
    "dataset_path = 'timeseries_all-patients_step-1_len-6391075.pkl'\n",
    "\n",
    "# group_id = 2\n",
    "# dataset_path = \"timeseries_\"+str(group_id)+\"-patients_step-1.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU; consider making n_epochs very small.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "save_every = 1\n",
    "test_every = save_every\n",
    "\n",
    "epoch_start = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print('Training on GPU!')\n",
    "else:\n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "\n",
    "lstm_trainer = train_lstm.LSTM_Trainer(seed, device)\n",
    "\n",
    "# heurisitic = models.Heuristic(1, 1).to(device)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Copy Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#load test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lstm_trainer\u001b[39m.\u001b[39;49mload_test(dataset_path, \u001b[39m1\u001b[39;49m, input_size, pred_horizon, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m data_loader \u001b[39m=\u001b[39m lstm_trainer\u001b[39m.\u001b[39mtest_loader\n",
      "File \u001b[1;32ml:\\Documents\\(8) Cairo Uni Spring 2023\\SBEN454_Machine_Learning\\Tasks & Projects\\Term Project\\CGM_Prediction_LSTM\\code\\train_lstm.py:49\u001b[0m, in \u001b[0;36mLSTM_Trainer.load_test\u001b[1;34m(self, dataset_path, batch_size, input_size, pred_horizon, amount)\u001b[0m\n\u001b[0;32m     46\u001b[0m [X_train, X_test, y_train, y_test] \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(dataset_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m amount \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset \u001b[39m=\u001b[39m SequenceDataset(\n\u001b[0;32m     50\u001b[0m         data\u001b[39m=\u001b[39;49mX_test,\n\u001b[0;32m     51\u001b[0m         target\u001b[39m=\u001b[39;49my_test,\n\u001b[0;32m     52\u001b[0m         sequence_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_horizon\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset \u001b[39m=\u001b[39m SequenceDataset(\n\u001b[0;32m     56\u001b[0m         data\u001b[39m=\u001b[39mX_test[:amount],\n\u001b[0;32m     57\u001b[0m         target\u001b[39m=\u001b[39my_test[:amount],\n\u001b[0;32m     58\u001b[0m         sequence_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_horizon\n\u001b[0;32m     59\u001b[0m     )\n",
      "File \u001b[1;32ml:\\Documents\\(8) Cairo Uni Spring 2023\\SBEN454_Machine_Learning\\Tasks & Projects\\Term Project\\CGM_Prediction_LSTM\\code\\train_lstm.py:194\u001b[0m, in \u001b[0;36mSequenceDataset.__init__\u001b[1;34m(self, data, target, sequence_length, device)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence_length \u001b[39m=\u001b[39m sequence_length\n\u001b[0;32m    193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(target)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m--> 194\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32ml:\\Documents\\(8) Cairo Uni Spring 2023\\SBEN454_Machine_Learning\\Tasks & Projects\\Term Project\\CGM_Prediction_LSTM\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#load test set\n",
    "lstm_trainer.load_test(dataset_path, 1, input_size, pred_horizon, 0)\n",
    "data_loader = lstm_trainer.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_loader)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(num_batches)\n\u001b[0;32m      3\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "num_batches = len(data_loader)\n",
    "print(num_batches)\n",
    "total_loss = 0\n",
    "\n",
    "import math\n",
    "\n",
    "start = time.time()\n",
    "esod = 0\n",
    "for X, y in data_loader:\n",
    "    last = X[0][-1]\n",
    "    prediction_full = last.repeat(1,pred_horizon)\n",
    "    #MSE\n",
    "    total_loss += loss_func(prediction_full, y).item()\n",
    "\n",
    "    #ESOD\n",
    "    # esod_pred = 0\n",
    "    # esod_y = 0\n",
    "    # preds = prediction_full.cpu().detach().numpy()[0]\n",
    "    # y_t = y.cpu().detach().numpy()[0]\n",
    "    # for j in range(2, len(preds)):\n",
    "    #     esod_pred += math.pow((preds[j] - 2*preds[j-1] + preds[j-2]), 2)\n",
    "    #     esod_y += math.pow((y_t[j] - 2*y_t[j-1] + y_t[j-2]), 2)\n",
    "    # if (esod_y != 0):\n",
    "    #     esod += esod_pred / esod_y\n",
    "    # break\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "avg_loss = total_loss / num_batches\n",
    "print(f\"Test loss: {avg_loss}\")\n",
    "print(\"avg ESOD:\", esod/num_batches)\n",
    "\n",
    "print(\"Time: \", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "lstm_trainer.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "[_, X_test, _, y_test] = pickle.load(open(dataset_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278215\n",
      "Test loss: 1874.4818803082146\n",
      "avg ESOD: 1.7893650743142147e-28\n",
      "Time:  784.2596719264984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "epochs = len(X_test)\n",
    "# epochs = 10000\n",
    "\n",
    "num_batches = len(X_test)\n",
    "print(num_batches)\n",
    "total_loss = 0\n",
    "esod = 0\n",
    "\n",
    "input_size = 5 \n",
    "start = time.time()\n",
    "for i in range(0,epochs):\n",
    "    X = X_test[i]\n",
    "    y = y_test[i]\n",
    "\n",
    "    last = X[-5:] \n",
    "    # prediction_full = last.repeat(1,pred_horizon)\n",
    "    reg = LinearRegression().fit(np.arange(0,input_size,1).reshape(input_size,1), last)\n",
    "    # m, c = np.linalg.lstsq(range(0,5), last)\n",
    "    # preds = m * np.linspace(6, 6+12, 1) + c\n",
    "    preds = reg.predict(np.arange(input_size,input_size+pred_horizon,1).reshape(pred_horizon,1))\n",
    "\n",
    "    # plt.scatter(np.arange(0,input_size,1), last)\n",
    "    # plt.scatter(np.arange(input_size,input_size+12,1), preds)\n",
    "    # plt.scatter(np.arange(input_size,input_size+12,1), y)\n",
    "\n",
    "    #MSE\n",
    "    prediction_full = torch.Tensor(preds.squeeze())\n",
    "    y_t = torch.Tensor(y)\n",
    "    total_loss += loss_func(prediction_full.squeeze(), y_t).item()\n",
    "\n",
    "    #ESOD\n",
    "    esod_pred = 0\n",
    "    esod_y = 0\n",
    "    preds2 = preds.squeeze()\n",
    "    for j in range(2, len(preds2)):\n",
    "        esod_pred += math.pow((preds2[j] - 2*preds2[j-1] + preds2[j-2]), 2)\n",
    "        esod_y += math.pow((y[j] - 2*y[j-1] + y[j-2]), 2)\n",
    "    if (esod_y != 0):\n",
    "        esod += esod_pred / esod_y\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "avg_loss = total_loss / epochs\n",
    "print(f\"Test loss: {avg_loss}\")\n",
    "print(\"avg ESOD:\", esod/num_batches)\n",
    "\n",
    "print(\"Time: \", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
