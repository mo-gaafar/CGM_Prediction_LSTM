{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "import models\n",
    "import train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(train_lstm)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1289719\n",
    "series_min_len = 144 #12hrs\n",
    "pred_horizon = 12 # 1hr\n",
    "input_size = series_min_len - pred_horizon\n",
    "output_size = pred_horizon\n",
    "\n",
    "dataset_path = 'timeseries_all-patients_step-1_len-6391075.pkl'\n",
    "\n",
    "# group_id = 2\n",
    "# dataset_path = \"timeseries_\"+str(group_id)+\"-patients_step-1.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "save_every = 1\n",
    "test_every = save_every\n",
    "\n",
    "epoch_start = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print('Training on GPU!')\n",
    "else:\n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "\n",
    "lstm_trainer = train_lstm.LSTM_Trainer(seed, device)\n",
    "\n",
    "# heurisitic = models.Heuristic(1, 1).to(device)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Copy Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load test set\n",
    "lstm_trainer.load_test(dataset_path, 1, input_size, pred_horizon, 0)\n",
    "data_loader = lstm_trainer.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_batches = len(data_loader)\n",
    "print(num_batches)\n",
    "total_loss = 0\n",
    "\n",
    "import math\n",
    "\n",
    "start = time.time()\n",
    "esod = 0\n",
    "for X, y in data_loader:\n",
    "    last = X[0][-1]\n",
    "    prediction_full = last.repeat(1,pred_horizon)\n",
    "    #MSE\n",
    "    total_loss += loss_func(prediction_full, y).item()\n",
    "\n",
    "    #ESOD\n",
    "    # esod_pred = 0\n",
    "    # esod_y = 0\n",
    "    # preds = prediction_full.cpu().detach().numpy()[0]\n",
    "    # y_t = y.cpu().detach().numpy()[0]\n",
    "    # for j in range(2, len(preds)):\n",
    "    #     esod_pred += math.pow((preds[j] - 2*preds[j-1] + preds[j-2]), 2)\n",
    "    #     esod_y += math.pow((y_t[j] - 2*y_t[j-1] + y_t[j-2]), 2)\n",
    "    # if (esod_y != 0):\n",
    "    #     esod += esod_pred / esod_y\n",
    "    # break\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "avg_loss = total_loss / num_batches\n",
    "print(f\"Test loss: {avg_loss}\")\n",
    "print(\"avg ESOD:\", esod/num_batches)\n",
    "\n",
    "print(\"Time: \", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm_trainer.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "[_, X_test, _, y_test] = pickle.load(open(dataset_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "epochs = len(X_test)\n",
    "# epochs = 10000\n",
    "\n",
    "num_batches = len(X_test)\n",
    "print(num_batches)\n",
    "total_loss = 0\n",
    "esod = 0\n",
    "\n",
    "input_size = 5 \n",
    "start = time.time()\n",
    "for i in range(0,epochs):\n",
    "    X = X_test[i]\n",
    "    y = y_test[i]\n",
    "\n",
    "    last = X[-5:] \n",
    "    # prediction_full = last.repeat(1,pred_horizon)\n",
    "    reg = LinearRegression().fit(np.arange(0,input_size,1).reshape(input_size,1), last)\n",
    "    # m, c = np.linalg.lstsq(range(0,5), last)\n",
    "    # preds = m * np.linspace(6, 6+12, 1) + c\n",
    "    preds = reg.predict(np.arange(input_size,input_size+pred_horizon,1).reshape(pred_horizon,1))\n",
    "\n",
    "    # plt.scatter(np.arange(0,input_size,1), last)\n",
    "    # plt.scatter(np.arange(input_size,input_size+12,1), preds)\n",
    "    # plt.scatter(np.arange(input_size,input_size+12,1), y)\n",
    "\n",
    "    #MSE\n",
    "    prediction_full = torch.Tensor(preds.squeeze())\n",
    "    y_t = torch.Tensor(y)\n",
    "    total_loss += loss_func(prediction_full.squeeze(), y_t).item()\n",
    "\n",
    "    #ESOD\n",
    "    esod_pred = 0\n",
    "    esod_y = 0\n",
    "    preds2 = preds.squeeze()\n",
    "    for j in range(2, len(preds2)):\n",
    "        esod_pred += math.pow((preds2[j] - 2*preds2[j-1] + preds2[j-2]), 2)\n",
    "        esod_y += math.pow((y[j] - 2*y[j-1] + y[j-2]), 2)\n",
    "    if (esod_y != 0):\n",
    "        esod += esod_pred / esod_y\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "avg_loss = total_loss / epochs\n",
    "print(f\"Test loss: {avg_loss}\")\n",
    "print(\"avg ESOD:\", esod/num_batches)\n",
    "\n",
    "print(\"Time: \", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
